{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amendments",
   "metadata": {},
   "source": [
    "<h3>Amendments Log</h3>\n",
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align:left\">Version</th>\n",
    "      <th style=\"text-align:left\">Amended By</th>\n",
    "      <th style=\"text-align:left\">Date</th>\n",
    "      <th style=\"text-align:left\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1.4</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Removed source_type column as it does not exist in Bronze.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.3</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Fixed Source Table path (pointed to 'bronze' schema) and removed resiliency checks.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.2</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Refactored to use Pandas for deduplication logic instead of SQL.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.1</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Updated deduplication logic to prioritize latest release date</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.0</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Initial Version</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imports-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MotherDuck...\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP & IMPORTS\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load Utils\n",
    "sys.path.append(os.getcwd())\n",
    "try:\n",
    "    from utils.db_utils import f_add_surrogate_key\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import utils\")\n",
    "\n",
    "# Load Env\n",
    "vLocalEnvPath = r\"C:/Users/garym/Documents/GitHub/MovieReleases/.env\"\n",
    "if os.path.exists(vLocalEnvPath):\n",
    "    load_dotenv(dotenv_path=vLocalEnvPath)\n",
    "else:\n",
    "    load_dotenv()\n",
    "\n",
    "vMdToken = os.getenv(\"MOTHERDUCK_TOKEN\")\n",
    "if not vMdToken: raise RuntimeError(\"MOTHERDUCK_TOKEN missing\")\n",
    "\n",
    "# Connect\n",
    "print(\"Connecting to MotherDuck...\")\n",
    "vCon = duckdb.connect(f\"md:?motherduck_token={vMdToken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS / CONSTANTS\n",
    "cNotebookName = \"process_dim_film.ipynb\"\n",
    "vTargetTable = \"MovieReleases.silver.film_release_dim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logic-md",
   "metadata": {},
   "source": [
    "## 2. Extract & Deduplicate (Pandas)\n",
    "We read the active Bronze history into a Pandas DataFrame and deduplicate using Python.\n",
    "We group by `imdb_id_ref` and keep the row with the most recent `valid_from_uda` (System Entry Date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "logic-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching active records from Bronze...\n",
      "Found 77 unique movies to process.\n",
      "Generating Surrogate Keys (sk_film_release) for MovieReleases.silver.film_release_dim...\n",
      "Target MovieReleases.silver.film_release_dim does not exist. Starting fresh SKs from 1.\n",
      "Loading to MovieReleases.silver.film_release_dim...\n",
      "Success.\n",
      "┌─────────────┬──────────────────────────────────────────┬─────────────────┐\n",
      "│ imdb_id_ref │               movie_title                │ sk_film_release │\n",
      "│   varchar   │                 varchar                  │      int64      │\n",
      "├─────────────┼──────────────────────────────────────────┼─────────────────┤\n",
      "│ tt30274401  │ Five Nights at Freddy's 2                │               1 │\n",
      "│ tt33978029  │ Ready or Not: Here I Come                │               2 │\n",
      "│ tt30825738  │ Star Wars: The Mandalorian and Grogu     │               3 │\n",
      "│ tt17490712  │ Mortal Kombat II                         │               4 │\n",
      "│ tt32565993  │ Three Bags Full: A Sheep Detective Movie │               5 │\n",
      "└─────────────┴──────────────────────────────────────────┴─────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Fetch Active Bronze Data\n",
    "print(\"Fetching active records from Bronze...\")\n",
    "try:\n",
    "    # Corrected Path: Read from 'bronze' schema which has the SCD2 columns\n",
    "    dfBronze = vCon.table(\"MovieReleases.bronze.uk_releases\").df()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading source table: {e}\")\n",
    "    dfBronze = pd.DataFrame()\n",
    "\n",
    "if not dfBronze.empty:\n",
    "    # 2. Filter Active\n",
    "    dfActive = dfBronze[dfBronze['is_current_uda'] == True].copy()\n",
    "    \n",
    "    # 3. Deduplicate (Pandas Logic)\n",
    "    # Sort by 'valid_from_uda' descending to put the latest system entry at the top\n",
    "    dfSorted = dfActive.sort_values(by='valid_from_uda', ascending=False)\n",
    "    \n",
    "    # Drop duplicates on Business Key (imdb_id_ref), keeping the first (latest)\n",
    "    dfDedup = dfSorted.drop_duplicates(subset=['imdb_id_ref'], keep='first').copy()\n",
    "    \n",
    "    # 4. Prepare Source Dataframe\n",
    "    # Removed source_type as it is not in the source table\n",
    "    dfSource = dfDedup[['imdb_id_ref', 'movie_title']].copy()\n",
    "    \n",
    "    # Ensure we don't have blank IDs\n",
    "    dfSource = dfSource.dropna(subset=['imdb_id_ref'])\n",
    "    \n",
    "    print(f\"Found {len(dfSource)} unique movies to process.\")\n",
    "\n",
    "    # 5. Generate/Maintain Surrogate Keys\n",
    "    dfDimFilm = f_add_surrogate_key(\n",
    "        vCon=vCon,\n",
    "        dfNewData=dfSource,\n",
    "        vTargetTableName=vTargetTable,\n",
    "        vBusinessKeyCol=\"imdb_id_ref\",\n",
    "        vSkColName=\"sk_film_release\"\n",
    "    )\n",
    "    \n",
    "    # 6. Load to Silver (Replace Table)\n",
    "    print(f\"Loading to {vTargetTable}...\")\n",
    "    vCon.sql(\"CREATE SCHEMA IF NOT EXISTS MovieReleases.silver\")\n",
    "    vCon.register('v_stage_dim_film', dfDimFilm)\n",
    "    vCon.sql(f\"CREATE OR REPLACE TABLE {vTargetTable} AS SELECT * FROM v_stage_dim_film\")\n",
    "    \n",
    "    print(\"Success.\")\n",
    "    # Validation\n",
    "    vCon.sql(f\"SELECT * FROM {vTargetTable} LIMIT 5\").show()\n",
    "\n",
    "else:\n",
    "    print(\"No data found in Bronze. Skipping Silver load.\")\n",
    "\n",
    "vCon.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
