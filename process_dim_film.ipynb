{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Amendments Log</h3>\n",
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align:left\">Version</th>\n",
    "      <th style=\"text-align:left\">Amended By</th>\n",
    "      <th style=\"text-align:left\">Date</th>\n",
    "      <th style=\"text-align:left\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1.6</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-12-07</td>\n",
    "      <td>Applied CI/CD fixes: Cleaned JSON IDs, added 'import sys'.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.5</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-12-02</td>\n",
    "      <td>Added extended metadata (Poster, Genres, Cast) to the dimension.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.4</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Removed source_type column as it does not exist in Bronze.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.3</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Fixed Source Table path (pointed to 'bronze' schema) and removed resiliency checks.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.2</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Refactored to use Pandas for deduplication logic instead of SQL.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.1</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Updated deduplication logic to prioritize latest release date</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.0</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Initial Version</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP & IMPORTS\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load Utils\n",
    "sys.path.append(os.getcwd())\n",
    "# Import DQ Utils & DB Utils\n",
    "try:\n",
    "    from utils.db_utils import f_add_surrogate_key\n",
    "    from utils.dq_utils import (\n",
    "        f_check_duplicate_rows, \n",
    "        f_check_duplicate_keys\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import utils\")\n",
    "\n",
    "# Load Env\n",
    "vLocalEnvPath = r\"C:/Users/garym/Documents/GitHub/MovieReleases/.env\"\n",
    "if os.path.exists(vLocalEnvPath):\n",
    "    load_dotenv(dotenv_path=vLocalEnvPath)\n",
    "else:\n",
    "    load_dotenv()\n",
    "\n",
    "vMdToken = os.getenv(\"MOTHERDUCK_TOKEN\")\n",
    "if not vMdToken: raise RuntimeError(\"MOTHERDUCK_TOKEN missing\")\n",
    "\n",
    "# Connect\n",
    "print(\"Connecting to MotherDuck...\")\n",
    "vCon = duckdb.connect(f\"md:?motherduck_token={vMdToken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS / CONSTANTS\n",
    "cNotebookName = \"process_dim_film.ipynb\"\n",
    "vTargetTable = \"MovieReleases.silver.film_release_dim\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract & Deduplicate (Pandas)\n",
    "We read the active Bronze history into a Pandas DataFrame and deduplicate using Python.\n",
    "We group by `imdb_id_ref` and keep the row with the most recent `valid_from_uda` (System Entry Date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fetch Active Bronze Data\n",
    "print(\"Fetching active records from Bronze...\")\n",
    "try:\n",
    "    # Corrected Path: Read from 'bronze' schema which has the SCD2 columns\n",
    "    dfBronze = vCon.table(\"MovieReleases.bronze.uk_releases\").df()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading source table: {e}\")\n",
    "    dfBronze = pd.DataFrame()\n",
    "\n",
    "if not dfBronze.empty:\n",
    "    # 2. Filter Active\n",
    "    dfActive = dfBronze[dfBronze['is_current_uda'] == True].copy()\n",
    "    \n",
    "    # 3. Deduplicate (Pandas Logic)\n",
    "    # Sort by 'valid_from_uda' descending to put the latest system entry at the top\n",
    "    dfSorted = dfActive.sort_values(by='valid_from_uda', ascending=False)\n",
    "    \n",
    "    # Drop duplicates on Business Key (imdb_id_ref), keeping the first (latest)\n",
    "    dfDedup = dfSorted.drop_duplicates(subset=['imdb_id_ref'], keep='first').copy()\n",
    "    \n",
    "    # 4. Prepare Source Dataframe\n",
    "    # Updated to include richer metadata from Bronze\n",
    "    vRequiredCols = ['imdb_id_ref', 'movie_title', 'poster_url', 'genres', 'cast_members']\n",
    "    \n",
    "    # Resiliency: Ensure cols exist (in case Bronze hasn't been reloaded yet)\n",
    "    vAvailableCols = [c for c in vRequiredCols if c in dfDedup.columns]\n",
    "    dfSource = dfDedup[vAvailableCols].copy()\n",
    "    \n",
    "    # Ensure we don't have blank IDs\n",
    "    dfSource = dfSource.dropna(subset=['imdb_id_ref'])\n",
    "    \n",
    "    print(f\"Found {len(dfSource)} unique movies to process.\")\n",
    "\n",
    "    # 5. Generate/Maintain Surrogate Keys\n",
    "    dfDimFilm = f_add_surrogate_key(\n",
    "        vCon=vCon,\n",
    "        dfNewData=dfSource,\n",
    "        vTargetTableName=vTargetTable,\n",
    "        vBusinessKeyCol=\"imdb_id_ref\",\n",
    "        vSkColName=\"sk_film_release\"\n",
    "    )\n",
    "    \n",
    "    # --- DATA QUALITY CHECKS ---\n",
    "    print(\"Running DQ Checks...\")\n",
    "    \n",
    "    # Check 1: No Duplicate Rows\n",
    "    f_check_duplicate_rows(vCon, dfDimFilm, cNotebookName, \"Silver\", vTargetTable)\n",
    "    \n",
    "    # Check 2: Unique Surrogate Keys\n",
    "    f_check_duplicate_keys(vCon, dfDimFilm, ['sk_film_release'], cNotebookName, \"Silver\", vTargetTable)\n",
    "    \n",
    "    # Check 3: Unique Business Keys (1 row per movie)\n",
    "    f_check_duplicate_keys(vCon, dfDimFilm, ['imdb_id_ref'], cNotebookName, \"Silver\", vTargetTable)\n",
    "\n",
    "    # 6. Load to Silver (Replace Table)\n",
    "    print(f\"Checks passed. Loading to {vTargetTable}...\")\n",
    "    vCon.sql(\"CREATE SCHEMA IF NOT EXISTS MovieReleases.silver\")\n",
    "    vCon.register('v_stage_dim_film', dfDimFilm)\n",
    "    vCon.sql(f\"CREATE OR REPLACE TABLE {vTargetTable} AS SELECT * FROM v_stage_dim_film\")\n",
    "    \n",
    "    print(\"Success.\")\n",
    "    # Validation\n",
    "    vCon.sql(f\"SELECT * FROM {vTargetTable} LIMIT 5\").show()\n",
    "\n",
    "else:\n",
    "    print(\"No data found in Bronze. Skipping Silver load.\")\n",
    "\n",
    "vCon.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}