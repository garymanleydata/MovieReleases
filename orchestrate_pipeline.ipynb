{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amendments",
   "metadata": {},
   "source": [
    "<h3>Amendments Log</h3>\n",
    "<table style=\"width:100%\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align:left\">Version</th>\n",
    "      <th style=\"text-align:left\">Amended By</th>\n",
    "      <th style=\"text-align:left\">Date</th>\n",
    "      <th style=\"text-align:left\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1.1</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-12-02</td>\n",
    "      <td>Added scheduling logic (Daily/Weekly/Monthly) filters.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1.0</td>\n",
    "      <td>Gary Manley</td>\n",
    "      <td>2025-11-30</td>\n",
    "      <td>Initial Version</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "description",
   "metadata": {},
   "source": [
    "# Orchestrator\n",
    "\n",
    "**Objective:** Master controller for the ETL pipeline.\n",
    "\n",
    "**Function:** \n",
    "1. Connects to MotherDuck `pipeline_control` table.\n",
    "2. Reads the active steps.\n",
    "3. **Filters steps based on Frequency** (Daily, Weekly, Monthly) vs Today's date.\n",
    "4. Uses `papermill` to execute the remaining notebooks in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP & IMPORTS\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Using forward slashes for path safety on Windows/Linux compatibility\n",
    "vLocalEnvPath = r\"C:/Users/garym/Documents/GitHub/MovieReleases/.env\"\n",
    "\n",
    "if os.path.exists(vLocalEnvPath):\n",
    "    # Local Mode: Load from specific file\n",
    "    load_dotenv(dotenv_path=vLocalEnvPath)\n",
    "    print(f\"Loaded local environment from {vLocalEnvPath}\")\n",
    "else:\n",
    "    # CI/CD Mode (GitHub Actions)\n",
    "    print(\"Local .env not found. Assuming CI/CD environment (Secrets already loaded).\")\n",
    "\n",
    "vMdToken = os.getenv(\"MOTHERDUCK_TOKEN\")\n",
    "if not vMdToken: raise RuntimeError(\"MOTHERDUCK_TOKEN missing\")\n",
    "\n",
    "print(f\"--- STARTING PIPELINE AT {datetime.now()} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS / CONSTANTS\n",
    "cNotebookName = \"orchestrate_pipeline.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fetch-markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch & Filter Schedule\n",
    "We fetch all active jobs, then filter them based on the current day/date matching the `job_frequency` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Connecting to MotherDuck to fetch schedule...\")\n",
    "    vCon = duckdb.connect(f\"md:?motherduck_token={vMdToken}\")\n",
    "    \n",
    "    # Read the control table\n",
    "    # We now fetch job_frequency and schedule_number\n",
    "    try:\n",
    "        vSql = \"\"\"\n",
    "            SELECT \n",
    "                step_id, \n",
    "                notebook_path, \n",
    "                description, \n",
    "                COALESCE(job_frequency, 'DAILY') as job_frequency, \n",
    "                COALESCE(schedule_number, 0) as schedule_number\n",
    "            FROM MovieReleases.main.pipeline_control \n",
    "            WHERE is_active = TRUE \n",
    "            ORDER BY step_id ASC\n",
    "        \"\"\"\n",
    "        dfAllSteps = vCon.sql(vSql).df()\n",
    "    except Exception as e:\n",
    "        print(\"Pipeline Control table not found or schema mismatch. Please run setup SQL.\")\n",
    "        print(f\"Error: {e}\")\n",
    "        dfAllSteps = pd.DataFrame()\n",
    "\n",
    "    vCon.close()\n",
    "    \n",
    "    if dfAllSteps.empty:\n",
    "        print(\"No active steps found. Exiting.\")\n",
    "    else:\n",
    "        print(f\"Found {len(dfAllSteps)} potentially active steps.\")\n",
    "        \n",
    "        # --- SCHEDULING LOGIC ---\n",
    "        vToday = datetime.now()\n",
    "        vIsoWeekDay = vToday.isoweekday() # 1=Mon, 7=Sun\n",
    "        vDayOfMonth = vToday.day\n",
    "        \n",
    "        print(f\"Date Check: Weekday={vIsoWeekDay}, DayOfMonth={vDayOfMonth}\")\n",
    "        \n",
    "        def f_should_run(row):\n",
    "            vFreq = str(row['job_frequency']).upper()\n",
    "            vNum = int(row['schedule_number'])\n",
    "            \n",
    "            if vFreq == 'DAILY':\n",
    "                return True\n",
    "            elif vFreq == 'WEEKLY':\n",
    "                # Runs only if today matches the schedule number (1-7)\n",
    "                return vNum == vIsoWeekDay\n",
    "            elif vFreq == 'MONTHLY':\n",
    "                # Runs only if today matches the day of month (1-31)\n",
    "                return vNum == vDayOfMonth\n",
    "            \n",
    "            return False\n",
    "\n",
    "        # Filter the DataFrame\n",
    "        dfSchedule = dfAllSteps[dfAllSteps.apply(f_should_run, axis=1)].copy()\n",
    "        print(f\"Steps scheduled for TODAY: {len(dfSchedule)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to fetch pipeline schedule: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execute-markdown",
   "metadata": {},
   "source": [
    "## 4. Execute Pipeline Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "vHasErrors = False\n",
    "\n",
    "if not dfSchedule.empty:\n",
    "    for vIndex, vRow in dfSchedule.iterrows():\n",
    "        vStepId = vRow['step_id']\n",
    "        vNotebook = vRow['notebook_path']\n",
    "        vDesc = vRow['description']\n",
    "        \n",
    "        print(f\"\\n>>> EXECUTION STEP {vStepId}: {vNotebook}\")\n",
    "        print(f\"    Description: {vDesc}\")\n",
    "        \n",
    "        # Define output path for logs\n",
    "        vLogDir = \"logs\"\n",
    "        os.makedirs(vLogDir, exist_ok=True)\n",
    "        vOutputNotebook = os.path.join(vLogDir, f\"out_{vNotebook}\")\n",
    "        \n",
    "        try:\n",
    "            vStart = time.time()\n",
    "            \n",
    "            # PAPERMILL: Runs the notebook\n",
    "            pm.execute_notebook(\n",
    "                input_path=vNotebook,\n",
    "                output_path=vOutputNotebook,\n",
    "                parameters=dict(vResetTable=False),\n",
    "                kernel_name='python3',\n",
    "                progress_bar=False, \n",
    "                stdout_file=sys.stdout\n",
    "            )\n",
    "            \n",
    "            vEnd = time.time()\n",
    "            print(f\"    [SUCCESS] Step {vStepId} completed in {round(vEnd - vStart, 2)}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    [FAILURE] Step {vStepId} failed: {e}\")\n",
    "            print(f\"    Check output notebook: {vOutputNotebook}\")\n",
    "            vHasErrors = True\n",
    "            break\n",
    "\n",
    "if vHasErrors:\n",
    "    raise RuntimeError(\"Pipeline Failed\")\n",
    "else:\n",
    "    print(\"\\n--- PIPELINE SUCCESS ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}